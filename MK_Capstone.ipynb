{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f779ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "### Analysis of Readmission Data for 10,000 Diabetics ###\n",
    "#########################################################\n",
    "\n",
    "\n",
    "# Load libraries\n",
    "library(RODBC) # for rodbc queries\n",
    "library(pandas)\n",
    "library(plotly) # for plotting\n",
    "library(tidyverse) # for data manipulation and graphing\n",
    "library(data.table)\n",
    "library(prettyR)\n",
    "library(DataExplorer) # data exploration\n",
    "library(caret)\n",
    "library(tictoc) #measures time\n",
    "library(xgboost)\n",
    "library(Matrix)\n",
    "library(fairml) # for bias and fairness assessment. Not used in final model.\n",
    "library(datarobot) # used to import model into Data Robot for bias/fairness\n",
    "\n",
    "\n",
    "#Load data\n",
    "import pandas as pd\n",
    "admit_dat = pd.read_csv ('readmissions.csv')\n",
    "\n",
    "#format data\n",
    "\n",
    "## no manipulation or transformation required in Python.  All work was done manually in Excel.\n",
    "admit_dat_sm <- sparse.model.matrix(IS_READMIT ~ . 0,\n",
    "                                    data - readmit_dat[,-c(1,\n",
    "                                                          which(colnames(readmit_dat) %in% c(\"testset\"))\n",
    "                                                          )\n",
    "                                                      ]\n",
    "                                   )\n",
    "\n",
    "#split data sets \n",
    "train_xgboost_dat <- readmit_dat_sm[noshow_dat$testset==FALSE,]\n",
    "test_xgboost_dat <- readmit_dat_sm[noshow_dat$testset==TRUE,]\n",
    "\n",
    "#create and store XGB matrices\n",
    "train_xgboost <- xgb.DMatrix(data = train_xgboost_dat, label = train_xgboost_label)\n",
    "test_xgboost <- xgb.DMatrix(data = train_xgboost_dat, label = train_xgboost_label)\n",
    "\n",
    "#parameter list for XGBoost model\n",
    "params <- list(booster = \"gbtree\",\n",
    "              objective = \"binary:logistic\",\n",
    "              eta = 0.1,\n",
    "              gamma = 0,\n",
    "              max_depth = 5,\n",
    "              min_child_weight = 1,\n",
    "              subsample = 0.7,\n",
    "              colsamply_bytree = 0.3,\n",
    "               scale_pos_weight = 1.0\n",
    "              )\n",
    "\n",
    "#train model\n",
    "tic(\"get\")\n",
    "xgb_model <- xgb.train(params = params,\n",
    "                      data = train_xgboost,\n",
    "                      nrounds = 200,\n",
    "                      watchlist - list(train=train.xgboost, test = test_xgboost),\n",
    "                      print_every_n = 25,\n",
    "                      early_stop_round = 10,\n",
    "                       maximize = F,\n",
    "                       eval_metric = \"auc\"\n",
    "                      )\n",
    "\n",
    "toc() #gets time elapsed\n",
    "\n",
    "#plotting\n",
    "#feature importance\n",
    "xgb_importance <- xgb.importance(features_names = colnames(train)xgboost_dat), model = xgb_model)\n",
    "xgb.plot.importance(importance_matrix = xgb_importance[1:20])\n",
    "\n",
    "#importance top 10\n",
    "xgb_importance %>%\n",
    "top_n(10, Gain) %>%\n",
    "ggplot(aes(x = reorder(Feature, Gain), y - Gain)) +\n",
    "geom_bar(stat = \"identity\", fill = \"#001111\", alpha = 0.7) + \n",
    "xlab(\"\") +\n",
    "scale_y_continuous(breaks = seq(0,.3, .05))+\n",
    "coord_flip()\n",
    "\n",
    "#retrieve predictions\n",
    "xgbpred <- predict(xgbmodel, test_xgboost)\n",
    "head(xgbpred)\n",
    "\n",
    "xgblabel <- getinfo(test_xgboost, \"label\")\n",
    "head(xgblabel)\n",
    "\n",
    "#ROC and AUC\n",
    "PRROC::roc.curve(scores.class= - fg, scores.class1 = bg, curve = TRUE)\n",
    "        \n",
    "pr.curve(scores.class0 = fg, scores.class1 = bg, curve = TRUE)\n",
    "\n",
    "rocauc3 <- PRROC::roc.curve(scores.class0 = fg, scores.class1 = bg, curve = TRUE)\n",
    "plot(rocauc3)\n",
    "\n",
    "ra3 <- pr.curve(scores.class0=fg, scores.class1=bg, curve = TRUE)\n",
    "plot(ra3)\n",
    "\n",
    "\n",
    "## Performance measurements\n",
    "xgbpred_label <- if_else(xgbpred >.5, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "xgbpred_label <- if_else(xgbpred > .6, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "xgbpred_label <- if_else(xgbpred >.7, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "xgbpred_label <- if_else(xgbpred > .8, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "xgbpred_label <- if_else(xgbpred >.9, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "xgbpred_label <- if_else(xgbpred > .92, 1, 0)\n",
    "confusionMatrix(table(xgbpred_label, xgblabel), positive = \"1\")\n",
    "\n",
    "##################################################\n",
    "## This is run within the datarobot environment ##\n",
    "##################################################\n",
    "\n",
    "\n",
    "#import into datarobot for bias and fairness\n",
    "import datarobot as dr\n",
    "\n",
    "# use execution_environment created earlier\n",
    "\n",
    "environment_version = dr.ExecutionEnvironmentVersion.create(\n",
    "    execution_environment.id,\n",
    "    docker_context_path=\"datarobot-user-models/public_dropin_environments/python3_pytorch\",\n",
    "    max_wait=None,  # set None to not block execution on this method\n",
    ")\n",
    "\n",
    "environment_version.id\n",
    "\n",
    "environment_version.build_status\n",
    "\n",
    "\n",
    "# after some time\n",
    "environment_version.refresh()\n",
    "environment_version.build_status\n",
    "\n",
    "\n",
    "#import model into datarobot\n",
    "custom_model = dr.CustomInferenceModel.create(\n",
    "    name='Python 3 PyTorch Custom Model',\n",
    "    target_type=dr.TARGET_TYPE.BINARY,\n",
    "    target_name='readmitted',\n",
    "    positive_class_label='False',\n",
    "    negative_class_label='True',\n",
    "    description='This is a Python3-based custom model. It has a simple PyTorch model built on 10k_diabetes dataset',\n",
    "    language='Python 3'\n",
    ")\n",
    "\n",
    "custom_model.id\n",
    "\n",
    "#### from here, the original code above is run in the datarobot environment\n",
    "#### syntax was updated in some cases\n",
    "####\n",
    "#\n",
    "#\n",
    "#\n",
    "# Remaining work to tune was done within datarobot GUI\n",
    "# all work on bias and fairness was done in datarobot GUI (no coding options available)\n",
    "# \n",
    "#\n",
    "#\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
